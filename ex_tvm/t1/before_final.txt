#[version = "0.0.5"]
def @main(%data: Tensor[(1, 3, 224, 224), float32], %conv1_1_weight: Tensor[(64, 3, 3, 3), float32], %conv1_1_bias: Tensor[(64), float32], %conv1_2_weight: Tensor[(64, 64, 3, 3), float32], %conv1_2_bias: Tensor[(64), float32], %conv2_1_weight: Tensor[(128, 64, 3, 3), float32], %conv2_1_bias: Tensor[(128), float32], %conv2_2_weight: Tensor[(128, 128, 3, 3), float32], %conv2_2_bias: Tensor[(128), float32], %conv3_1_weight: Tensor[(256, 128, 3, 3), float32], %conv3_1_bias: Tensor[(256), float32], %conv3_2_weight: Tensor[(256, 256, 3, 3), float32], %conv3_2_bias: Tensor[(256), float32], %conv3_3_weight: Tensor[(256, 256, 3, 3), float32], %conv3_3_bias: Tensor[(256), float32], %conv4_1_weight: Tensor[(512, 256, 3, 3), float32], %conv4_1_bias: Tensor[(512), float32], %conv4_2_weight: Tensor[(512, 512, 3, 3), float32], %conv4_2_bias: Tensor[(512), float32], %conv4_3_weight: Tensor[(512, 512, 3, 3), float32], %conv4_3_bias: Tensor[(512), float32], %conv5_1_weight: Tensor[(512, 512, 3, 3), float32], %conv5_1_bias: Tensor[(512), float32], %conv5_2_weight: Tensor[(512, 512, 3, 3), float32], %conv5_2_bias: Tensor[(512), float32], %conv5_3_weight: Tensor[(512, 512, 3, 3), float32], %conv5_3_bias: Tensor[(512), float32], %fc6_weight: Tensor[(4096, 25088), float32], %fc6_bias: Tensor[(4096), float32], %fc7_weight: Tensor[(4096, 4096), float32], %fc7_bias: Tensor[(4096), float32], %fc8_weight: Tensor[(1000, 4096), float32], %fc8_bias: Tensor[(1000), float32]) -> Tensor[(1, 1000), float32] {
  %0 = nn.conv2d(%data, %conv1_1_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 224, 224), float32] */;
  %1 = nn.bias_add(%0, %conv1_1_bias) /* ty=Tensor[(1, 64, 224, 224), float32] */;
  %2 = nn.relu(%1) /* ty=Tensor[(1, 64, 224, 224), float32] */;
  %3 = nn.conv2d(%2, %conv1_2_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 224, 224), float32] */;
  %4 = nn.bias_add(%3, %conv1_2_bias) /* ty=Tensor[(1, 64, 224, 224), float32] */;
  %5 = nn.relu(%4) /* ty=Tensor[(1, 64, 224, 224), float32] */;
  %6 = nn.max_pool2d(%5, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 112, 112), float32] */;
  %7 = nn.conv2d(%6, %conv2_1_weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 112, 112), float32] */;
  %8 = nn.bias_add(%7, %conv2_1_bias) /* ty=Tensor[(1, 128, 112, 112), float32] */;
  %9 = nn.relu(%8) /* ty=Tensor[(1, 128, 112, 112), float32] */;
  %10 = nn.conv2d(%9, %conv2_2_weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 112, 112), float32] */;
  %11 = nn.bias_add(%10, %conv2_2_bias) /* ty=Tensor[(1, 128, 112, 112), float32] */;
  %12 = nn.relu(%11) /* ty=Tensor[(1, 128, 112, 112), float32] */;
  %13 = nn.max_pool2d(%12, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 56, 56), float32] */;
  %14 = nn.conv2d(%13, %conv3_1_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;
  %15 = nn.bias_add(%14, %conv3_1_bias) /* ty=Tensor[(1, 256, 56, 56), float32] */;
  %16 = nn.relu(%15) /* ty=Tensor[(1, 256, 56, 56), float32] */;
  %17 = nn.conv2d(%16, %conv3_2_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;
  %18 = nn.bias_add(%17, %conv3_2_bias) /* ty=Tensor[(1, 256, 56, 56), float32] */;
  %19 = nn.relu(%18) /* ty=Tensor[(1, 256, 56, 56), float32] */;
  %20 = nn.conv2d(%19, %conv3_3_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;
  %21 = nn.bias_add(%20, %conv3_3_bias) /* ty=Tensor[(1, 256, 56, 56), float32] */;
  %22 = nn.relu(%21) /* ty=Tensor[(1, 256, 56, 56), float32] */;
  %23 = nn.max_pool2d(%22, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 256, 28, 28), float32] */;
  %24 = nn.conv2d(%23, %conv4_1_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;
  %25 = nn.bias_add(%24, %conv4_1_bias) /* ty=Tensor[(1, 512, 28, 28), float32] */;
  %26 = nn.relu(%25) /* ty=Tensor[(1, 512, 28, 28), float32] */;
  %27 = nn.conv2d(%26, %conv4_2_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;
  %28 = nn.bias_add(%27, %conv4_2_bias) /* ty=Tensor[(1, 512, 28, 28), float32] */;
  %29 = nn.relu(%28) /* ty=Tensor[(1, 512, 28, 28), float32] */;
  %30 = nn.conv2d(%29, %conv4_3_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;
  %31 = nn.bias_add(%30, %conv4_3_bias) /* ty=Tensor[(1, 512, 28, 28), float32] */;
  %32 = nn.relu(%31) /* ty=Tensor[(1, 512, 28, 28), float32] */;
  %33 = nn.max_pool2d(%32, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 14, 14), float32] */;
  %34 = nn.conv2d(%33, %conv5_1_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;
  %35 = nn.bias_add(%34, %conv5_1_bias) /* ty=Tensor[(1, 512, 14, 14), float32] */;
  %36 = nn.relu(%35) /* ty=Tensor[(1, 512, 14, 14), float32] */;
  %37 = nn.conv2d(%36, %conv5_2_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;
  %38 = nn.bias_add(%37, %conv5_2_bias) /* ty=Tensor[(1, 512, 14, 14), float32] */;
  %39 = nn.relu(%38) /* ty=Tensor[(1, 512, 14, 14), float32] */;
  %40 = nn.conv2d(%39, %conv5_3_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;
  %41 = nn.bias_add(%40, %conv5_3_bias) /* ty=Tensor[(1, 512, 14, 14), float32] */;
  %42 = nn.relu(%41) /* ty=Tensor[(1, 512, 14, 14), float32] */;
  %43 = nn.max_pool2d(%42, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 7, 7), float32] */;
  %44 = nn.batch_flatten(%43) /* ty=Tensor[(1, 25088), float32] */;
  %45 = nn.dense(%44, %fc6_weight, units=4096) /* ty=Tensor[(1, 4096), float32] */;
  %46 = nn.bias_add(%45, %fc6_bias, axis=-1) /* ty=Tensor[(1, 4096), float32] */;
  %47 = nn.relu(%46) /* ty=Tensor[(1, 4096), float32] */;
  %48 = nn.dropout(%47) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;
  %49 = %48.0;
  %50 = nn.dense(%49, %fc7_weight, units=4096) /* ty=Tensor[(1, 4096), float32] */;
  %51 = nn.bias_add(%50, %fc7_bias, axis=-1) /* ty=Tensor[(1, 4096), float32] */;
  %52 = nn.relu(%51) /* ty=Tensor[(1, 4096), float32] */;
  %53 = nn.dropout(%52) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;
  %54 = %53.0;
  %55 = nn.dense(%54, %fc8_weight, units=1000) /* ty=Tensor[(1, 1000), float32] */;
  %56 = nn.bias_add(%55, %fc8_bias, axis=-1) /* ty=Tensor[(1, 1000), float32] */;
  nn.softmax(%56) /* ty=Tensor[(1, 1000), float32] */
}